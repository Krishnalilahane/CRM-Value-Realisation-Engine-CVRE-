{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596931bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: {'accounts': 500, 'contacts': 1416, 'leads': 1500, 'opportunities': 900, 'activities': 3879}\n",
      "\n",
      "Opportunities — column check (top 25):\n",
      "['opp_id', 'lead_id', 'account_id', 'created_date', 'stage', 'amount', 'expected_close_date', 'outcome', 'win_probability_estimated', 'stage_jump_flag', 'backward_stage_change_count', 'days_in_stage_current']\n",
      "\n",
      "Opportunities — % missing (relevant fields):\n",
      "expected_close_date          30.00\n",
      "amount                       12.56\n",
      "win_probability_estimated     0.00\n",
      "stage                         0.00\n",
      "created_date                  0.00\n",
      "dtype: float64\n",
      "\n",
      "Amount sanity:\n",
      "count       787.00\n",
      "mean      26400.22\n",
      "std       16919.51\n",
      "min        3515.00\n",
      "10%       10399.20\n",
      "25%       14825.50\n",
      "50%       22598.00\n",
      "75%       32536.00\n",
      "90%       46903.60\n",
      "95%       57051.70\n",
      "max      131704.00\n",
      "Name: amount, dtype: float64\n",
      "\n",
      "Win probability sanity:\n",
      "count    900.0000\n",
      "mean       0.4547\n",
      "std        0.1913\n",
      "min        0.0500\n",
      "10%        0.1910\n",
      "25%        0.3202\n",
      "50%        0.4561\n",
      "75%        0.6044\n",
      "90%        0.7087\n",
      "95%        0.7647\n",
      "max        0.8927\n",
      "Name: win_probability_estimated, dtype: float64\n",
      "\n",
      "Activity coverage check (opportunity-level):\n",
      "count    900.00\n",
      "mean       4.31\n",
      "std        3.58\n",
      "min        0.00\n",
      "25%        1.00\n",
      "50%        4.00\n",
      "75%        7.00\n",
      "max       11.00\n",
      "Name: activity_count, dtype: float64\n",
      "Pct with 0 activities: 22.44 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = \"./data/raw\" \n",
    "\n",
    "accounts = pd.read_csv(f\"{DATA_DIR}/accounts.csv\")\n",
    "contacts = pd.read_csv(f\"{DATA_DIR}/contacts.csv\")\n",
    "leads = pd.read_csv(f\"{DATA_DIR}/leads.csv\")\n",
    "opps = pd.read_csv(f\"{DATA_DIR}/opportunities.csv\")\n",
    "acts = pd.read_csv(f\"{DATA_DIR}/activities.csv\")\n",
    "\n",
    "def _snakecase_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "                 .str.lower()\n",
    "                 .str.replace(\" \", \"_\")\n",
    "                 .str.replace(\"-\", \"_\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "accounts = _snakecase_cols(accounts)\n",
    "contacts = _snakecase_cols(contacts)\n",
    "leads = _snakecase_cols(leads)\n",
    "opps = _snakecase_cols(opps)\n",
    "acts = _snakecase_cols(acts)\n",
    "\n",
    "print(\"Rows:\", {\n",
    "    \"accounts\": len(accounts),\n",
    "    \"contacts\": len(contacts),\n",
    "    \"leads\": len(leads),\n",
    "    \"opportunities\": len(opps),\n",
    "    \"activities\": len(acts)\n",
    "})\n",
    "\n",
    "print(\"\\nOpportunities — column check (top 25):\")\n",
    "print(list(opps.columns)[:25])\n",
    "\n",
    "# --- Fast missingness snapshot for fields that will drive EV & leakage ---\n",
    "key_fields = [\n",
    "    \"opportunity_id\", \"amount\", \"win_probability_estimated\", \"expected_close_date\",\n",
    "    \"stage\", \"stage_entered_date\", \"last_stage_change_date\", \"created_date\",\n",
    "    \"days_in_stage\", \"days_since_last_activity\"\n",
    "]\n",
    "present = [c for c in key_fields if c in opps.columns]\n",
    "\n",
    "missing_snapshot = (opps[present].isna().mean().sort_values(ascending=False) * 100).round(2)\n",
    "print(\"\\nOpportunities — % missing (relevant fields):\")\n",
    "print(missing_snapshot)\n",
    "\n",
    "# --- Basic distribution sanity for amount and win prob (if present) ---\n",
    "if \"amount\" in opps.columns:\n",
    "    print(\"\\nAmount sanity:\")\n",
    "    print(opps[\"amount\"].describe(percentiles=[.1, .25, .5, .75, .9, .95]).round(2))\n",
    "\n",
    "if \"win_probability_estimated\" in opps.columns:\n",
    "    print(\"\\nWin probability sanity:\")\n",
    "    print(opps[\"win_probability_estimated\"].describe(percentiles=[.1, .25, .5, .75, .9, .95]).round(4))\n",
    "\n",
    "opp_key = None\n",
    "for k in [\"opportunity_id\", \"opp_id\", \"oppty_id\"]:\n",
    "    if k in opps.columns:\n",
    "        opp_key = k\n",
    "        break\n",
    "\n",
    "act_opp_key = None\n",
    "for k in [\"opportunity_id\", \"opp_id\", \"oppty_id\"]:\n",
    "    if k in acts.columns:\n",
    "        act_opp_key = k\n",
    "        break\n",
    "\n",
    "if opp_key and act_opp_key:\n",
    "    act_counts = acts.groupby(act_opp_key).size().rename(\"activity_count\").reset_index()\n",
    "    opps_prof = opps[[opp_key]].merge(act_counts, how=\"left\", left_on=opp_key, right_on=act_opp_key)\n",
    "    opps_prof[\"activity_count\"] = opps_prof[\"activity_count\"].fillna(0).astype(int)\n",
    "\n",
    "    print(\"\\nActivity coverage check (opportunity-level):\")\n",
    "    print(opps_prof[\"activity_count\"].describe().round(2))\n",
    "    print(\"Pct with 0 activities:\", round((opps_prof[\"activity_count\"] == 0).mean() * 100, 2), \"%\")\n",
    "else:\n",
    "    print(\"\\nNOTE: Could not find a common opportunity key between opportunities and activities.\")\n",
    "    print(\"Opportunities keys tried: opportunity_id / opp_id / oppty_id\")\n",
    "    print(\"Activities keys tried: opportunity_id / opp_id / oppty_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06ed035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV model locked:\n",
      "- Opportunities: 900\n",
      "- Total Pipeline (Amount, €): 23,320,176\n",
      "- Total Pipeline EV (€, Amount × WinProb): 10,707,050\n",
      "\n",
      "Missing Amount Handling (CRM hygiene impact):\n",
      "- Missing amount (count): 113\n",
      "- Missing amount (% of opps): 12.56%\n",
      "- Share of pipeline € from imputed values: 10.91%\n",
      "\n",
      "Stage-level imputation + EV (top stages by EV):\n",
      "         stage  opp_count  missing_amount  median_amount_stage  \\\n",
      "1   Closed Won        426              64              22369.5   \n",
      "0  Closed Lost        257              24              22920.0   \n",
      "3     Proposal        115              14              22933.0   \n",
      "2  Negotiation        102              11              21856.0   \n",
      "\n",
      "   pipeline_amount   pipeline_ev  missing_amount_pct  \n",
      "1       11154028.0  5.836100e+06               15.02  \n",
      "0        6460740.0  2.534350e+06                9.34  \n",
      "3        3091420.0  1.357397e+06               12.17  \n",
      "2        2613988.0  9.792032e+05               10.78  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Standardize core fields\n",
    "opps_m2 = opps.copy()\n",
    "\n",
    "# Safety: ensure numeric\n",
    "opps_m2[\"win_probability_estimated\"] = pd.to_numeric(opps_m2[\"win_probability_estimated\"], errors=\"coerce\")\n",
    "opps_m2[\"amount\"] = pd.to_numeric(opps_m2[\"amount\"], errors=\"coerce\")\n",
    "\n",
    "# 2) Stage-median imputation for missing amount (explainable, not ML)\n",
    "stage_medians = opps_m2.groupby(\"stage\")[\"amount\"].median()\n",
    "overall_median = opps_m2[\"amount\"].median()\n",
    "\n",
    "opps_m2[\"amount_imputed_flag\"] = opps_m2[\"amount\"].isna()\n",
    "\n",
    "opps_m2[\"amount_imputed\"] = opps_m2[\"amount\"]\n",
    "opps_m2.loc[opps_m2[\"amount_imputed\"].isna(), \"amount_imputed\"] = (\n",
    "    opps_m2.loc[opps_m2[\"amount_imputed\"].isna(), \"stage\"].map(stage_medians)\n",
    ")\n",
    "\n",
    "# fallback to overall median if stage median missing\n",
    "opps_m2[\"amount_imputed\"] = opps_m2[\"amount_imputed\"].fillna(overall_median)\n",
    "\n",
    "# 3) Expected Value\n",
    "# EV = amount * win_probability\n",
    "opps_m2[\"ev\"] = opps_m2[\"amount_imputed\"] * opps_m2[\"win_probability_estimated\"]\n",
    "\n",
    "# 4) Executive defensibility snapshots\n",
    "total_pipeline_amount = opps_m2[\"amount_imputed\"].sum()\n",
    "total_pipeline_ev = opps_m2[\"ev\"].sum()\n",
    "\n",
    "imputed_count = int(opps_m2[\"amount_imputed_flag\"].sum())\n",
    "imputed_pct = round(opps_m2[\"amount_imputed_flag\"].mean() * 100, 2)\n",
    "\n",
    "imputed_amount_share = round(\n",
    "    (opps_m2.loc[opps_m2[\"amount_imputed_flag\"], \"amount_imputed\"].sum() / total_pipeline_amount) * 100,\n",
    "    2\n",
    ")\n",
    "\n",
    "print(\"EV model locked:\")\n",
    "print(f\"- Opportunities: {len(opps_m2)}\")\n",
    "print(f\"- Total Pipeline (Amount, €): {total_pipeline_amount:,.0f}\")\n",
    "print(f\"- Total Pipeline EV (€, Amount × WinProb): {total_pipeline_ev:,.0f}\")\n",
    "\n",
    "print(\"\\nMissing Amount Handling (CRM hygiene impact):\")\n",
    "print(f\"- Missing amount (count): {imputed_count}\")\n",
    "print(f\"- Missing amount (% of opps): {imputed_pct}%\")\n",
    "print(f\"- Share of pipeline € from imputed values: {imputed_amount_share}%\")\n",
    "\n",
    "# Optional: stage-level imputation transparency\n",
    "stage_impute_table = (\n",
    "    opps_m2.groupby(\"stage\")\n",
    "    .agg(\n",
    "        opp_count=(\"opp_id\", \"count\"),\n",
    "        missing_amount=(\"amount_imputed_flag\", \"sum\"),\n",
    "        median_amount_stage=(\"amount_imputed\", \"median\"),\n",
    "        pipeline_amount=(\"amount_imputed\", \"sum\"),\n",
    "        pipeline_ev=(\"ev\", \"sum\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "stage_impute_table[\"missing_amount_pct\"] = (\n",
    "    (stage_impute_table[\"missing_amount\"] / stage_impute_table[\"opp_count\"]) * 100\n",
    ").round(2)\n",
    "\n",
    "stage_impute_table = stage_impute_table.sort_values(\"pipeline_ev\", ascending=False)\n",
    "\n",
    "print(\"\\nStage-level imputation + EV (top stages by EV):\")\n",
    "print(stage_impute_table.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8fee029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leads columns:\n",
      "['lead_id', 'contact_id', 'account_id', 'lead_source', 'assigned_owner', 'created_date', 'mql_date', 'initial_response_time_hours', 'quality_true']\n",
      "\n",
      "No precomputed response-duration column found. Trying timestamp-based computation...\n",
      "Created timestamp candidates found: ['created_date']\n",
      "Responded timestamp candidates found: []\n",
      "\n",
      "BLOCKER: Leads table has neither a response-duration column nor usable timestamps.\n",
      "We can still run leakage for other behaviours now, and add lead SLA leakage once schema supports it.\n"
     ]
    }
   ],
   "source": [
    "print(\"Leads columns:\")\n",
    "print(list(leads.columns))\n",
    "\n",
    "# Candidate duration columns commonly used in synthetic CRM datasets\n",
    "duration_candidates = [\n",
    "    \"response_time_hours\", \"lead_response_hours\", \"response_hours\",\n",
    "    \"time_to_first_response_hours\", \"first_response_hours\",\n",
    "    \"first_response_time_hours\", \"sla_response_hours\"\n",
    "]\n",
    "\n",
    "found_duration = [c for c in duration_candidates if c in leads.columns]\n",
    "\n",
    "if found_duration:\n",
    "    dur_col = found_duration[0]\n",
    "    print(f\"\\nFound lead response duration column: {dur_col}\")\n",
    "    leads_sla = leads[[\"lead_id\", dur_col]].copy()\n",
    "    leads_sla[dur_col] = pd.to_numeric(leads_sla[dur_col], errors=\"coerce\")\n",
    "    leads_sla[\"slow_lead_response_flag\"] = leads_sla[dur_col] > 48\n",
    "    print(\"\\nSLA flags computed from duration column.\")\n",
    "else:\n",
    "    print(\"\\nNo precomputed response-duration column found. Trying timestamp-based computation...\")\n",
    "\n",
    "    # Candidate timestamp pairs\n",
    "    created_candidates = [\"created_date\", \"lead_created_date\", \"lead_created_at\", \"created_at\"]\n",
    "    responded_candidates = [\"first_response_date\", \"responded_date\", \"first_contacted_date\",\n",
    "                            \"first_response_at\", \"responded_at\", \"first_contacted_at\"]\n",
    "\n",
    "    created_found = [c for c in created_candidates if c in leads.columns]\n",
    "    responded_found = [c for c in responded_candidates if c in leads.columns]\n",
    "\n",
    "    print(\"Created timestamp candidates found:\", created_found)\n",
    "    print(\"Responded timestamp candidates found:\", responded_found)\n",
    "\n",
    "    if created_found and responded_found:\n",
    "        created_col = created_found[0]\n",
    "        responded_col = responded_found[0]\n",
    "\n",
    "        tmp = leads[[\"lead_id\", created_col, responded_col]].copy()\n",
    "        tmp[created_col] = pd.to_datetime(tmp[created_col], errors=\"coerce\")\n",
    "        tmp[responded_col] = pd.to_datetime(tmp[responded_col], errors=\"coerce\")\n",
    "\n",
    "        tmp[\"lead_response_hours_calc\"] = (tmp[responded_col] - tmp[created_col]).dt.total_seconds() / 3600.0\n",
    "        tmp[\"slow_lead_response_flag\"] = tmp[\"lead_response_hours_calc\"] > 48\n",
    "\n",
    "        leads_sla = tmp[[\"lead_id\", \"lead_response_hours_calc\", \"slow_lead_response_flag\"]].copy()\n",
    "\n",
    "        print(\"\\nComputed lead response hours from timestamps.\")\n",
    "        print(leads_sla[\"lead_response_hours_calc\"].describe().round(2))\n",
    "    else:\n",
    "        print(\"\\nBLOCKER: Leads table has neither a response-duration column nor usable timestamps.\")\n",
    "        print(\"We can still run leakage for other behaviours now, and add lead SLA leakage once schema supports it.\")\n",
    "        leads_sla = None\n",
    "\n",
    "# Preview flags if available\n",
    "if leads_sla is not None:\n",
    "    print(\"\\nSlow lead response rate (>48h):\",\n",
    "          round(leads_sla[\"slow_lead_response_flag\"].mean() * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e6b709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behaviour</th>\n",
       "      <th>affected_opportunities</th>\n",
       "      <th>affected_pipeline_ev_eur</th>\n",
       "      <th>assumed_ev_haircut_pct</th>\n",
       "      <th>estimated_ev_leakage_eur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stalled 30D</td>\n",
       "      <td>678</td>\n",
       "      <td>7758752.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1939688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Activity</td>\n",
       "      <td>202</td>\n",
       "      <td>1946439.0</td>\n",
       "      <td>20</td>\n",
       "      <td>389288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stage Jump</td>\n",
       "      <td>161</td>\n",
       "      <td>1931933.0</td>\n",
       "      <td>10</td>\n",
       "      <td>193193.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     behaviour  affected_opportunities  affected_pipeline_ev_eur  \\\n",
       "2  Stalled 30D                     678                 7758752.0   \n",
       "0  No Activity                     202                 1946439.0   \n",
       "1   Stage Jump                     161                 1931933.0   \n",
       "\n",
       "   assumed_ev_haircut_pct  estimated_ev_leakage_eur  \n",
       "2                      25                 1939688.0  \n",
       "0                      20                  389288.0  \n",
       "1                      10                  193193.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- 1) Activity coverage flag ----\n",
    "act_counts = acts.groupby(\"opp_id\").size().rename(\"activity_count\").reset_index()\n",
    "opps_lkg = opps_m2.merge(act_counts, on=\"opp_id\", how=\"left\")\n",
    "opps_lkg[\"activity_count\"] = opps_lkg[\"activity_count\"].fillna(0).astype(int)\n",
    "opps_lkg[\"no_activity_flag\"] = opps_lkg[\"activity_count\"] == 0\n",
    "\n",
    "# ---- 2) Stalled deal flag (>30 days) ----\n",
    "opps_lkg[\"stalled_30d_flag\"] = opps_lkg[\"days_in_stage_current\"] > 30\n",
    "\n",
    "# ---- 3) Stage movement flags ----\n",
    "opps_lkg[\"stage_jump_flag\"] = opps_lkg[\"stage_jump_flag\"].fillna(False).astype(bool)\n",
    "opps_lkg[\"backward_stage_flag\"] = opps_lkg[\"backward_stage_change_count\"].fillna(0) > 0\n",
    "\n",
    "# ---- 4) Lead SLA join (if available) ----\n",
    "if leads_sla is not None:\n",
    "    opps_lkg = opps_lkg.merge(leads_sla[[\"lead_id\", \"slow_lead_response_flag\"]], on=\"lead_id\", how=\"left\")\n",
    "    opps_lkg[\"slow_lead_response_flag\"] = opps_lkg[\"slow_lead_response_flag\"].fillna(False).astype(bool)\n",
    "else:\n",
    "    opps_lkg[\"slow_lead_response_flag\"] = False  # placeholder, not computed\n",
    "\n",
    "# ---- 5) Haircut assumptions (explicit) ----\n",
    "HAIRCUTS = {\n",
    "    \"slow_lead_response_flag\": 0.15,\n",
    "    \"no_activity_flag\": 0.20,\n",
    "    \"stage_jump_flag\": 0.10,\n",
    "    \"stalled_30d_flag\": 0.25\n",
    "}\n",
    "\n",
    "computed_flags = [\"no_activity_flag\", \"stage_jump_flag\", \"stalled_30d_flag\"]\n",
    "if leads_sla is not None:\n",
    "    computed_flags = [\"slow_lead_response_flag\"] + computed_flags\n",
    "\n",
    "# ---- 6) Leakage per behaviour ----\n",
    "rows = []\n",
    "for flag in computed_flags:\n",
    "    haircut = HAIRCUTS[flag]\n",
    "    affected = opps_lkg[opps_lkg[flag]]\n",
    "    rows.append({\n",
    "        \"behaviour\": flag.replace(\"_flag\", \"\").replace(\"_\", \" \").title(),\n",
    "        \"affected_opportunities\": len(affected),\n",
    "        \"affected_pipeline_ev_eur\": round(affected[\"ev\"].sum(), 0),\n",
    "        \"assumed_ev_haircut_pct\": int(haircut * 100),\n",
    "        \"estimated_ev_leakage_eur\": round(affected[\"ev\"].sum() * haircut, 0)\n",
    "    })\n",
    "\n",
    "leakage_table = pd.DataFrame(rows).sort_values(\"estimated_ev_leakage_eur\", ascending=False)\n",
    "\n",
    "leakage_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4498686a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead SLA snapshot:\n",
      "Pct within 24h: 55.0 %\n",
      "Pct within 48h: 75.87 %\n",
      "Pct slow (>48h): 24.13 %\n",
      "\n",
      "Slow flag columns after merge: ['slow_lead_response_flag_opps', 'slow_lead_response_flag_leads']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behaviour</th>\n",
       "      <th>affected_opportunities</th>\n",
       "      <th>affected_pipeline_ev_eur</th>\n",
       "      <th>assumed_ev_haircut_pct</th>\n",
       "      <th>estimated_ev_leakage_eur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stalled 30D</td>\n",
       "      <td>678</td>\n",
       "      <td>7758752.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1939688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Activity</td>\n",
       "      <td>202</td>\n",
       "      <td>1946439.0</td>\n",
       "      <td>20</td>\n",
       "      <td>389288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slow Lead Response</td>\n",
       "      <td>218</td>\n",
       "      <td>1689692.0</td>\n",
       "      <td>15</td>\n",
       "      <td>253454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stage Jump</td>\n",
       "      <td>161</td>\n",
       "      <td>1931933.0</td>\n",
       "      <td>10</td>\n",
       "      <td>193193.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            behaviour  affected_opportunities  affected_pipeline_ev_eur  \\\n",
       "3         Stalled 30D                     678                 7758752.0   \n",
       "1         No Activity                     202                 1946439.0   \n",
       "0  Slow Lead Response                     218                 1689692.0   \n",
       "2          Stage Jump                     161                 1931933.0   \n",
       "\n",
       "   assumed_ev_haircut_pct  estimated_ev_leakage_eur  \n",
       "3                      25                 1939688.0  \n",
       "1                      20                  389288.0  \n",
       "0                      15                  253454.0  \n",
       "2                      10                  193193.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build lead SLA flags from correct column\n",
    "leads_sla = leads[[\"lead_id\", \"initial_response_time_hours\"]].copy()\n",
    "leads_sla[\"initial_response_time_hours\"] = pd.to_numeric(leads_sla[\"initial_response_time_hours\"], errors=\"coerce\")\n",
    "\n",
    "leads_sla[\"slow_lead_response_flag\"] = leads_sla[\"initial_response_time_hours\"] > 48\n",
    "leads_sla[\"within_24h_flag\"] = leads_sla[\"initial_response_time_hours\"] <= 24\n",
    "leads_sla[\"within_48h_flag\"] = leads_sla[\"initial_response_time_hours\"] <= 48\n",
    "\n",
    "print(\"Lead SLA snapshot:\")\n",
    "print(\"Pct within 24h:\", round(leads_sla[\"within_24h_flag\"].mean() * 100, 2), \"%\")\n",
    "print(\"Pct within 48h:\", round(leads_sla[\"within_48h_flag\"].mean() * 100, 2), \"%\")\n",
    "print(\"Pct slow (>48h):\", round(leads_sla[\"slow_lead_response_flag\"].mean() * 100, 2), \"%\")\n",
    "\n",
    "# Merge safely (handle existing placeholder column in opps_lkg)\n",
    "opps_lkg2 = opps_lkg.merge(\n",
    "    leads_sla[[\"lead_id\", \"slow_lead_response_flag\"]],\n",
    "    on=\"lead_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_opps\", \"_leads\")\n",
    ")\n",
    "\n",
    "# Detect which slow flag column exists after merge\n",
    "slow_cols = [c for c in opps_lkg2.columns if \"slow_lead_response_flag\" in c]\n",
    "print(\"\\nSlow flag columns after merge:\", slow_cols)\n",
    "\n",
    "# Prefer the leads-derived one if present\n",
    "if \"slow_lead_response_flag_leads\" in opps_lkg2.columns:\n",
    "    opps_lkg2[\"slow_lead_response_flag\"] = opps_lkg2[\"slow_lead_response_flag_leads\"]\n",
    "elif \"slow_lead_response_flag\" in opps_lkg2.columns:\n",
    "    opps_lkg2[\"slow_lead_response_flag\"] = opps_lkg2[\"slow_lead_response_flag\"]\n",
    "elif \"slow_lead_response_flag_opps\" in opps_lkg2.columns:\n",
    "    opps_lkg2[\"slow_lead_response_flag\"] = opps_lkg2[\"slow_lead_response_flag_opps\"]\n",
    "else:\n",
    "    raise ValueError(\"No slow_lead_response_flag column found after merge — unexpected schema state.\")\n",
    "\n",
    "opps_lkg2[\"slow_lead_response_flag\"] = opps_lkg2[\"slow_lead_response_flag\"].fillna(False).astype(bool)\n",
    "\n",
    "# Haircuts (explicit)\n",
    "HAIRCUTS = {\n",
    "    \"slow_lead_response_flag\": 0.15,\n",
    "    \"no_activity_flag\": 0.20,\n",
    "    \"stage_jump_flag\": 0.10,\n",
    "    \"stalled_30d_flag\": 0.25\n",
    "}\n",
    "\n",
    "# Leakage table rebuild\n",
    "rows = []\n",
    "for flag, haircut in HAIRCUTS.items():\n",
    "    affected = opps_lkg2[opps_lkg2[flag]]\n",
    "    rows.append({\n",
    "        \"behaviour\": flag.replace(\"_flag\", \"\").replace(\"_\", \" \").title(),\n",
    "        \"affected_opportunities\": len(affected),\n",
    "        \"affected_pipeline_ev_eur\": round(affected[\"ev\"].sum(), 0),\n",
    "        \"assumed_ev_haircut_pct\": int(haircut * 100),\n",
    "        \"estimated_ev_leakage_eur\": round(affected[\"ev\"].sum() * haircut, 0)\n",
    "    })\n",
    "\n",
    "leakage_table_full = pd.DataFrame(rows).sort_values(\"estimated_ev_leakage_eur\", ascending=False)\n",
    "\n",
    "leakage_table_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5be887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage totals:\n",
      "- Non-deduped (sum of drivers): €2,775,623\n",
      "- Deduped (max haircut per opp): €2,084,151\n",
      "- Deduped leakage as % of total EV (€10.71M): 19.47%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>assumption_summary</th>\n",
       "      <th>estimated_ev_leakage_recovered_eur</th>\n",
       "      <th>recovered_pct_of_deduped_leakage</th>\n",
       "      <th>recovered_pct_of_total_ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D_FULL_PACKAGE</td>\n",
       "      <td>Deduped per opp: max( haircut × recovery_rate ...</td>\n",
       "      <td>844552.0</td>\n",
       "      <td>40.52</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_STALL_GOVERNANCE</td>\n",
       "      <td>stalled 30d @ 40% recovery</td>\n",
       "      <td>775875.0</td>\n",
       "      <td>37.23</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_EVIDENCE_GATE</td>\n",
       "      <td>no activity @ 50% recovery, stage jump @ 40% r...</td>\n",
       "      <td>250428.0</td>\n",
       "      <td>12.02</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_SLA_48H</td>\n",
       "      <td>slow lead response @ 60% recovery</td>\n",
       "      <td>152072.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scenario                                 assumption_summary  \\\n",
       "3      D_FULL_PACKAGE  Deduped per opp: max( haircut × recovery_rate ...   \n",
       "2  C_STALL_GOVERNANCE                         stalled 30d @ 40% recovery   \n",
       "1     B_EVIDENCE_GATE  no activity @ 50% recovery, stage jump @ 40% r...   \n",
       "0           A_SLA_48H                  slow lead response @ 60% recovery   \n",
       "\n",
       "   estimated_ev_leakage_recovered_eur  recovered_pct_of_deduped_leakage  \\\n",
       "3                            844552.0                             40.52   \n",
       "2                            775875.0                             37.23   \n",
       "1                            250428.0                             12.02   \n",
       "0                            152072.0                              7.30   \n",
       "\n",
       "   recovered_pct_of_total_ev  \n",
       "3                       7.89  \n",
       "2                       7.25  \n",
       "1                       2.34  \n",
       "0                       1.42  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "FLAGS = [\"slow_lead_response_flag\", \"no_activity_flag\", \"stage_jump_flag\", \"stalled_30d_flag\"]\n",
    "\n",
    "HAIRCUTS = {\n",
    "    \"slow_lead_response_flag\": 0.15,\n",
    "    \"no_activity_flag\": 0.20,\n",
    "    \"stage_jump_flag\": 0.10,\n",
    "    \"stalled_30d_flag\": 0.25\n",
    "}\n",
    "\n",
    "# 1) Deduped total leakage: apply max haircut per opp \n",
    "def max_haircut(row):\n",
    "    hc = 0.0\n",
    "    for f in FLAGS:\n",
    "        if bool(row[f]):\n",
    "            hc = max(hc, HAIRCUTS[f])\n",
    "    return hc\n",
    "\n",
    "opps_cf = opps_lkg2.copy()\n",
    "\n",
    "opps_cf[\"max_haircut\"] = opps_cf.apply(max_haircut, axis=1)\n",
    "opps_cf[\"deduped_leakage_eur\"] = opps_cf[\"ev\"] * opps_cf[\"max_haircut\"]\n",
    "\n",
    "total_leakage_nondedup = leakage_table_full[\"estimated_ev_leakage_eur\"].sum()\n",
    "total_leakage_dedup = opps_cf[\"deduped_leakage_eur\"].sum()\n",
    "\n",
    "print(\"Leakage totals:\")\n",
    "print(f\"- Non-deduped (sum of drivers): €{total_leakage_nondedup:,.0f}\")\n",
    "print(f\"- Deduped (max haircut per opp): €{total_leakage_dedup:,.0f}\")\n",
    "print(f\"- Deduped leakage as % of total EV (€10.71M): {round((total_leakage_dedup/10707050)*100, 2)}%\")\n",
    "\n",
    "# ---- 2) Scenario recovery rates (explicit) ----\n",
    "RECOVERY_RATES = {\n",
    "    \"A_SLA_48H\": {\n",
    "        \"slow_lead_response_flag\": 0.60\n",
    "    },\n",
    "    \"B_EVIDENCE_GATE\": {\n",
    "        \"no_activity_flag\": 0.50,\n",
    "        \"stage_jump_flag\": 0.40\n",
    "    },\n",
    "    \"C_STALL_GOVERNANCE\": {\n",
    "        \"stalled_30d_flag\": 0.40\n",
    "    }\n",
    "}\n",
    "\n",
    "# ---- 3) Scenario recovery per opp (deduped within scenario) ----\n",
    "def scenario_recovery(row, scenario_map):\n",
    "    # compute potential recovery haircuts for triggered behaviours in scenario\n",
    "    rec_hc = 0.0\n",
    "    for f, rec_rate in scenario_map.items():\n",
    "        if bool(row[f]):\n",
    "            rec_hc = max(rec_hc, HAIRCUTS[f] * rec_rate)\n",
    "    return row[\"ev\"] * rec_hc\n",
    "\n",
    "scenario_rows = []\n",
    "\n",
    "for scen, fmap in RECOVERY_RATES.items():\n",
    "    opps_cf[f\"recovery_{scen}\"] = opps_cf.apply(lambda r: scenario_recovery(r, fmap), axis=1)\n",
    "    scenario_rows.append({\n",
    "        \"scenario\": scen,\n",
    "        \"assumption_summary\": \", \".join([f\"{k.replace('_flag','').replace('_',' ')} @ {int(v*100)}% recovery\"\n",
    "                                         for k,v in fmap.items()]),\n",
    "        \"estimated_ev_leakage_recovered_eur\": round(opps_cf[f\"recovery_{scen}\"].sum(), 0)\n",
    "    })\n",
    "\n",
    "scenario_table = pd.DataFrame(scenario_rows)\n",
    "\n",
    "# ---- 4) Full package (A+B+C) — deduped across all included behaviours ----\n",
    "full_map = {}\n",
    "for scen in RECOVERY_RATES:\n",
    "    full_map.update(RECOVERY_RATES[scen])\n",
    "\n",
    "opps_cf[\"recovery_FULL_PACKAGE\"] = opps_cf.apply(lambda r: scenario_recovery(r, full_map), axis=1)\n",
    "\n",
    "full_row = pd.DataFrame([{\n",
    "    \"scenario\": \"D_FULL_PACKAGE\",\n",
    "    \"assumption_summary\": \"Deduped per opp: max( haircut × recovery_rate ) across SLA + Evidence Gate + Stall Governance\",\n",
    "    \"estimated_ev_leakage_recovered_eur\": round(opps_cf[\"recovery_FULL_PACKAGE\"].sum(), 0)\n",
    "}])\n",
    "\n",
    "scenario_table = pd.concat([scenario_table, full_row], ignore_index=True)\n",
    "\n",
    "# ---- 5) Add context: recovered € as % of deduped leakage + total EV ----\n",
    "scenario_table[\"recovered_pct_of_deduped_leakage\"] = (\n",
    "    scenario_table[\"estimated_ev_leakage_recovered_eur\"] / total_leakage_dedup * 100\n",
    ").round(2)\n",
    "\n",
    "scenario_table[\"recovered_pct_of_total_ev\"] = (\n",
    "    scenario_table[\"estimated_ev_leakage_recovered_eur\"] / opps_cf[\"ev\"].sum() * 100\n",
    ").round(2)\n",
    "\n",
    "scenario_table = scenario_table.sort_values(\"estimated_ev_leakage_recovered_eur\", ascending=False)\n",
    "\n",
    "scenario_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196c589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
